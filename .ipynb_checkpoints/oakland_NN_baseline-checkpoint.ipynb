{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "#from utils import Cutout\n",
    "\n",
    "class part_pytorch_dataset(data.Dataset):\n",
    "    def __init__(self,x,y,train=True,transform=None, target_transform=None,float_target=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        if (train):\n",
    "            self.train_data = x\n",
    "            self.train_labels = y\n",
    "        else:\n",
    "            self.test_data = x\n",
    "            self.test_labels = y\n",
    "        self.float_target =  float_target\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        #img = Image.fromarray(img, mode='L')\n",
    "\n",
    "        #print (self.transform)\n",
    "        #print (img.shape)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            new_img = self.transform(img)\n",
    "        else:\n",
    "            new_img = torch.from_numpy(np.array(img)).type(torch.FloatTensor)\n",
    "\n",
    "        #if self.target_transform is not None:\n",
    "        #    new_target = self.target_transform(target)\n",
    "        #else:\n",
    "            #print (target)\n",
    "        if (not self.float_target):\n",
    "            new_target = torch.from_numpy(np.array(target)).type(torch.LongTensor)\n",
    "        else:\n",
    "            new_target = torch.from_numpy(np.array(target)).type(torch.FloatTensor)\n",
    "\n",
    "        #print (new_target)\n",
    "\n",
    "        #print (\"new img type\",type(new_img))\n",
    "        #new_img.share_memory_()\n",
    "        #new_target.share_memory_()\n",
    "\n",
    "        return new_img.type(torch.FloatTensor), new_target, index\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "class oakland_whitebox_attacknet_fcgradient(nn.Module):\n",
    "\n",
    "    def __init__(self,dim):\n",
    "        dim1 = int(dim[0])\n",
    "        dim2 = int(dim[1])\n",
    "        print(\"dim2\",dim2)\n",
    "        super(oakland_whitebox_attacknet_fcgradient,self).__init__()\n",
    "        self.drop1 = nn.Dropout(p=0.2,inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=100,kernel_size=(1,dim2),stride=1)\n",
    "        self.activation1 = nn.ReLU(inplace=True)\n",
    "        self.drop2 = nn.Dropout(p=0.2,inplace=True)\n",
    "        self.fc1 = nn.Linear(1,2024)\n",
    "        self.activation2 = nn.ReLU(inplace=True)\n",
    "        self.drop3 = nn.Dropout(p=0.2,inplace=True)\n",
    "        self.fc2 = nn.Linear(2024,512)\n",
    "        self.activation3 = nn.ReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(512,256)\n",
    "        self.activation4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        #### layers above are to process the gradient of fc layer\n",
    "\n",
    "        self.fc4 = nn.Linear(256,256)\n",
    "        self.activation5 = nn.ReLU(inplace=True)\n",
    "        self.fc5 = nn.Linear(256,128)\n",
    "        self.activation6 = nn.ReLU(inplace=True)\n",
    "        self.fc6 = nn.Linear(128,64)\n",
    "        self.activation7 = nn.ReLU(inplace=True)\n",
    "        self.fc7 = nn.Linear(64,1)\n",
    "        self.activation8 = nn.ReLU(inplace=True)\n",
    "\n",
    "        #### layers above are the components of the encoder network\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.activation4(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.activation5(x)\n",
    "        x = self.fc5(x)\n",
    "        x = self.activation6(x)\n",
    "        x = self.fc6(x)\n",
    "        x = self.activation7(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.activation8(x)\n",
    "        return x\n",
    "    ### here we only use the gradient wrt the last layer as input and use a CNN to process the data\n",
    "    ###\n",
    "    \n",
    "def gradient_analysis(dataset_name,model_name,training_size,evaluation_size,epochs):\n",
    "    \n",
    "    attack_batch_size = 100\n",
    "    batch_size = 100\n",
    "    attack_learning_rate = 0.01\n",
    "    attack_training_epochs = 20\n",
    "    \n",
    "    for epoch in epochs:\n",
    "        naming_str = str(epoch)+\"_\"+str(dataset_name)+\"_\"+str(training_size)+\"_\"+str(evaluation_size)+\"_\"+str(model_name)+\".npy\"\n",
    "        data_name = \"./expdata/expdata/all_info_non_member_lastlayergradient0_0.0_0_0.0_0_\" + naming_str\n",
    "        \n",
    "        gradient_data = np.load(data_name)\n",
    "        \n",
    "        print (gradient_data.shape)\n",
    "        \n",
    "        true_label = np.concatenate((np.ones(evaluation_size),np.zeros(evaluation_size))).astype(np.int64)\n",
    "        \n",
    "        for user in range(1):\n",
    "            this_data = gradient_data[user,:,:,:]\n",
    "            this_data = np.reshape(this_data,(2*evaluation_size,100,256,1))\n",
    "            \n",
    "            train_index = np.random.choice(len(true_label),int(1/2*len(true_label)),replace=False)\n",
    "            test_index = np.setdiff1d(np.arange(len(true_label)),train_index)\n",
    "            \n",
    "            this_train_data = this_data[train_index]\n",
    "            this_test_data = this_data[test_index]\n",
    "            this_train_label = true_label[train_index]\n",
    "            this_test_label = true_label[test_index]\n",
    "            \n",
    "            \n",
    "            this_train_dataset = part_pytorch_dataset(x=this_train_data,y=this_train_label,transform=None)\n",
    "            this_train_data_loader = torch.utils.data.DataLoader(this_train_dataset, batch_size=attack_batch_size,shuffle=True, num_workers=1)\n",
    "            \n",
    "            this_test_dataset = part_pytorch_dataset(x=this_test_data,y=this_test_label,transform=None)\n",
    "            this_test_data_loader = torch.utils.data.DataLoader(this_test_dataset, batch_size=attack_batch_size,shuffle=True, num_workers=1)\n",
    "            \n",
    "            model = oakland_whitebox_attacknet_fcgradient([this_data.shape[1],this_data.shape[2]])\n",
    "            \n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            criterion = nn.CrossEntropyLoss().to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=attack_learning_rate, momentum=0.9, weight_decay=1e-6)\n",
    "            \n",
    "            for attack_training_epoch in range(attack_training_epochs):\n",
    "                model.train()\n",
    "                \n",
    "                for images,labels,_ in this_train_data_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    print (images.size())\n",
    "                    model.zero_grad()\n",
    "                    log_probs = model(images)\n",
    "                    loss = criterion(log_probs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            \n",
    "                correct = 0.0\n",
    "                total = 0.0\n",
    "                model.eval()\n",
    "                for images, labels,_ in this_train_data_loader:\n",
    "                    images = images.to(device)\n",
    "                    outputs = model(images)\n",
    "                    labels = labels.to(device)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum()\n",
    "                acc = correct.item()\n",
    "                acc = acc / total\n",
    "                acc = acc * 100.0\n",
    "                \n",
    "                print(\"epoch %d, training accuracy %.2f\" %(attack_training_epochs,acc))\n",
    "                \n",
    "            \n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            model.eval()\n",
    "            for images, labels,_ in this_test_data_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                labels = labels.to(device)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            acc = correct.item()\n",
    "            acc = acc / total\n",
    "            acc = acc * 100.0\n",
    "            \n",
    "            print (\"final testing accuracy %.2f \" %(acc))\n",
    "            \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1000, 100, 256)\n",
      "torch.Size([100, 100, 256, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 100 1 1 256, expected input[100, 100, 256, 1] to have 1 channels, but got 100 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fc0aaeb677f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradient_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cifar100'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'alexnet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevaluation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-6eac7ffa742a>\u001b[0m in \u001b[0;36mgradient_analysis\u001b[0;34m(dataset_name, model_name, training_size, evaluation_size, epochs)\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6eac7ffa742a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 100 1 1 256, expected input[100, 100, 256, 1] to have 1 channels, but got 100 channels instead"
     ]
    }
   ],
   "source": [
    "gradient_analysis(dataset_name='cifar100',model_name='alexnet',training_size=5000,evaluation_size=500,epochs=[50,100,150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
