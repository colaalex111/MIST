{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7007fa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_seed = 0\n",
    "import numpy as np\n",
    "np.random.seed(this_seed)\n",
    "import sklearn\n",
    "sklearn.utils.check_random_state(this_seed)\n",
    "eps1 = 1e-6\n",
    "eps2 = 1e-10\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "def logit_function(l):\n",
    "    ### we need to setup some bounds for probability (or loss) for numerical stability\n",
    "    eps = eps1\n",
    "    l = np.clip(l,a_min=eps,a_max=1-eps)\n",
    "    return np.log(l/(1-l))\n",
    "    \n",
    "import math\n",
    "def normpdf(x, mean, sd):\n",
    "    var = float(sd)**2\n",
    "    denom = (2*math.pi*var)**.5\n",
    "    num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "    return num/denom\n",
    "\n",
    "def get_blackbox_auc_lira(all_pred,all_train_index, all_valid_index, all_class_label, fpr_threshold_list=[1e-4,1e-3]):\n",
    "\t## prepare membership label and all probablities\n",
    "\tnum_instance = len(all_train_index[0]) + len(all_valid_index[0])\n",
    "\t\n",
    "\tall_metric_result = []\n",
    "\tall_labels = []\n",
    "\tavg_vul = []\n",
    "\tfor i in range(num_instance):\n",
    "\t\tthis_instance_pred = []\n",
    "\t\tthis_instance_label = []\n",
    "\t\tthis_instance_index = []\n",
    "\t\tthis_instance_prob = []\n",
    "\t\tfor j in range(len(all_train_index)):\n",
    "\t\t\tif (i in all_train_index[j]):\n",
    "\t\t\t\tthis_instance_label.append(1)\n",
    "\t\t\t\tthis_instance_index.append( all_train_index[j].tolist().index(i))\n",
    "\t\t\t\tthis_instance_pred.append( all_pred[j][this_instance_index[-1]])\n",
    "\t\t\t\tthis_pred = this_instance_pred[-1]\n",
    "\t\t\t\tthis_label = all_class_label[j][this_instance_index[-1]]\n",
    "\t\t\t\tthis_instance_prob.append( this_pred[this_label])\n",
    "\t\t\telse:\n",
    "\t\t\t\tthis_instance_label.append(0)\n",
    "\t\t\t\tthis_instance_index.append( all_valid_index[j].tolist().index(i) + len(all_train_index[j]))\n",
    "\t\t\t\tthis_instance_pred.append( all_pred[j][this_instance_index[-1]])\n",
    "\t\t\t\tthis_pred = this_instance_pred[-1]\n",
    "\t\t\t\tthis_label = all_class_label[j][this_instance_index[-1]]\n",
    "\t\t\t\tthis_instance_prob.append( this_pred[this_label])\n",
    "\t\t\t\n",
    "\t\tthis_instance_label = np.array(this_instance_label)\n",
    "\t\tthis_instance_index = np.array(this_instance_index)\n",
    "\t\tthis_instance_pred = np.array(this_instance_pred)\n",
    "\t\t\n",
    "\t\t#print (i,len(all_train_index),len(this_instance_label),len(this_instance_prob),len(this_instance_index))\n",
    "\t\t#print (this_instance_prob)\n",
    "\t\t#this_instance_prob = logit_function(np.array(this_instance_prob).flatten())\n",
    "\t\tthis_instance_prob = np.array(this_instance_prob).flatten()\n",
    "\t\t#print (this_instance_prob)\n",
    "\t\t# select half of member and half of nonmember as training samples\n",
    "\t\t# remaining half of members and half of nonmembers are testing sample\n",
    "\t\thalf = int(0.5*len(this_instance_label))\n",
    "\t\t#print (half)\n",
    "\t\ttraining_index = np.random.choice(len(this_instance_label),half,replace=False)\n",
    "\t\ttesting_index = np.setdiff1d(np.arange(len(this_instance_label)),training_index)\n",
    "\n",
    "\t\ttraining_member_index = []\n",
    "\t\ttraining_nonmember_index = []\n",
    "\t\tfor this_idx in training_index:\n",
    "\t\t\tif (this_instance_label[this_idx] == 1):\n",
    "\t\t\t\ttraining_member_index.append(this_idx)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttraining_nonmember_index.append(this_idx)\n",
    "\t\ttraining_nonmember_index = np.array(training_nonmember_index).astype(np.int64)\n",
    "\t\ttraining_member_index = np.array(training_member_index).astype(np.int64)\n",
    "\t\ttraining_member_prob = this_instance_prob[training_member_index]\n",
    "\t\ttraining_nonmember_prob = this_instance_prob[training_nonmember_index]\n",
    "\t\tin_mu,in_std = np.average(training_member_prob),np.std(training_member_prob)\n",
    "\t\t# calculate out distribution\n",
    "\t\tout_mu,out_std = np.average(training_nonmember_prob),np.std(training_nonmember_prob)\n",
    "\t\t# calculate metric\n",
    "\t\t#print (in_mu,in_std,out_mu,out_std)\n",
    "\t\tthis_instance_metric = []\n",
    "\t\tthis_instance_metric_label = []\n",
    "\t\teps = eps2\n",
    "\t\tfor idx in testing_index:\n",
    "\t\t\t#print (testing_index[idx])\n",
    "\t\t\t#print (len(this_instance_prob))\n",
    "\t\t\t#print (len(this_instance_label))\n",
    "\t\t\tthis_prob = this_instance_prob[idx]\n",
    "\t\t\tthis_label = this_instance_label[idx]\n",
    "\t\t\tin_prob = normpdf(this_prob,in_mu,in_std+eps) \n",
    "\t\t\tout_prob = normpdf(this_prob,out_mu,out_std+eps)\n",
    "\t\t\t#print (in_prob,out_prob)\n",
    "\t\t\tthis_metric = in_prob / (out_prob+eps)\n",
    "\t\t\tthis_instance_metric.append(this_metric)\n",
    "\t\t\tthis_instance_metric_label.append(this_label)\n",
    "\t\t\t#if (this_label == 1 and this_instance_metric == 0.0):\n",
    "\t\t\t#\tprint (in_mu,in_std,out_mu,out_std,this_prob)\n",
    "\t\t## only sample fixed in and fixed out for eval\n",
    "\t\tthis_instance_metric_label = np.array(this_instance_metric_label)\n",
    "\t\tthis_instance_metric = np.array(this_instance_metric)\n",
    "\t\t#fixed_num = 5\n",
    "\t\t#print (np.bincount(this_instance_metric_label))\n",
    "\t\t#if (np.any(np.bincount(this_instance_metric_label)<fixed_num) or len(np.bincount(this_instance_metric_label))<2):\n",
    "\t\t#\tcontinue\n",
    "\t\tall_in_index = np.arange(len(this_instance_metric_label))[this_instance_metric_label == 1]\n",
    "\t\tall_out_index = np.arange(len(this_instance_metric_label))[this_instance_metric_label == 0]\n",
    "\t\tall_out_metric = this_instance_metric[all_out_index]\n",
    "\t\tall_in_metric = this_instance_metric[all_in_index]\n",
    "\t\tavg_vul.append(np.median(all_in_metric) - np.median(all_out_metric))\n",
    "        \n",
    "\t\tall_metric_result.append(this_instance_metric)\n",
    "\t\tall_labels.append(this_instance_metric_label)\n",
    "\t\n",
    "\tall_metric_result = np.array(all_metric_result).flatten()\n",
    "\tall_metric_result = np.nan_to_num(all_metric_result)\n",
    "\tall_labels = np.array(all_labels).flatten()\n",
    "\t\n",
    "\tpos_index = np.arange(len(all_labels))[all_labels == 1]\n",
    "\tneg_index = np.arange(len(all_labels))[all_labels == 0]\n",
    "\tmin_len = min(len(pos_index),len(neg_index))\n",
    "\tsampled_pos_index = np.random.choice(pos_index,min_len,replace=False)\n",
    "\tsampled_neg_index = np.random.choice(neg_index,min_len,replace=False)\n",
    "\tsampled_index = np.concatenate((sampled_neg_index,sampled_pos_index),axis=0)\n",
    "\tall_metric_result = all_metric_result[sampled_index]\n",
    "\tall_labels = all_labels[sampled_index]\n",
    "\t#print (all_metric_result.shape,all_labels.shape)\n",
    "\t#print (all_metric_result[:100],all_labels[:100])\n",
    "\t## calcualte AUC and PLR\n",
    "\tauc = roc_auc_score(all_labels,all_metric_result)\n",
    "\tprint(f\"AUC score {auc}\")\n",
    "\tfor fpr_threshold in fpr_threshold_list:\n",
    "\t\tnegative_index = np.arange(len(all_labels))[all_labels == 0]\n",
    "\t\tthreshold_index = int(len(negative_index)*fpr_threshold)\n",
    "\t\tthreshold = np.sort(all_metric_result[negative_index])[::-1][threshold_index]\n",
    "\t\tprint(f\"Likelihood threshold {threshold}\")\n",
    "\t\tcnt = 0\n",
    "\t\tfor i in range(len(all_metric_result)):\n",
    "\t\t\tif (all_metric_result[i] >= threshold and all_labels[i]==1):\n",
    "\t\t\t\tcnt += 1\n",
    "\t\tprint(f\"TPR {cnt/len(negative_index)}, FPR {fpr_threshold}, PLR {cnt / threshold_index}\")\n",
    "\tfpr,tpr, _ =  metrics.roc_curve(all_labels, all_metric_result, pos_label=1)\n",
    "\treturn all_metric_result,all_labels,auc,1.0*cnt/threshold_index,fpr,tpr,np.array(avg_vul)\n",
    "\n",
    "\n",
    "def get_blackbox_auc_no_shadow(all_train_loss, all_test_loss, fpr_threshold=0.001):\n",
    "\t### randomly sample to get a balanced evaluation set\n",
    "\tmin_len = min(len(all_test_loss), len(all_train_loss))\n",
    "\ttest_index = np.random.choice(np.arange(len(all_test_loss)), min_len, replace=False)\n",
    "\tall_test_loss = all_test_loss[test_index]\n",
    "\ttrain_index = np.random.choice(np.arange(len(all_train_loss)), min_len, replace=False)\n",
    "\tall_train_loss = all_train_loss[train_index]\n",
    "\t\n",
    "\t## calcualte AUC and PLR\n",
    "\tlabel = np.concatenate((np.ones((len(all_train_loss))), np.zeros((len(all_test_loss)))))\n",
    "\tauc = roc_auc_score(label, np.concatenate((all_train_loss, all_test_loss), axis=0) * -1)\n",
    "\tprint(f\"AUC score {auc}\")\n",
    "\t\n",
    "\tthreshold = np.sort(all_test_loss)[int(len(all_test_loss) * fpr_threshold)]\n",
    "\tprint(f\"Loss threshold {threshold}\")\n",
    "\t\n",
    "\tcnt = 0\n",
    "\tfor i in range(len(all_train_loss)):\n",
    "\t\tif (all_train_loss[i] <= threshold):\n",
    "\t\t\tcnt += 1\n",
    "\tprint(f\"TPR {cnt / min_len}, FPR {fpr_threshold}, PLR {cnt / (min_len * fpr_threshold)}\")\n",
    "\t\n",
    "\treturn auc, 1.0 * cnt / (min_len * fpr_threshold), np.concatenate((all_train_loss, all_test_loss), axis=0) * -1, label\n",
    "\n",
    "def log_roc(metric,label):\n",
    "    fpr, tpr, thresholds = roc_curve(label, metric, pos_label=1)\n",
    "    fpr = fpr[::-1]\n",
    "    tpr = tpr[::-1]\n",
    "    d = {}\n",
    "    for x,y in zip(fpr,tpr):\n",
    "        if (x in d):\n",
    "            continue\n",
    "        d[x] = y\n",
    "    new_fpr = list(d.keys())\n",
    "    new_tpr = list(d.values())\n",
    "    fpr = np.array(new_fpr)[::-1]\n",
    "    tpr = np.array(new_tpr)[::-1]\n",
    "    \n",
    "    uniform_fpr = [1e-4] + [1e-4*i*2 for i in range(1,6)] + [1e-3*i/2 for i in range(2,20)]\n",
    "    uniform_fpr = uniform_fpr + [1e-2*i/2 for i in range(2,200)] #+ [1e-1*i for i in range(1,11)]\n",
    "    uniform_tpr = []\n",
    "    for _,this_fpr in enumerate(uniform_fpr):\n",
    "        for j in range(len(fpr)):\n",
    "            if (fpr[j]>=this_fpr):\n",
    "                this_tpr = tpr[j]\n",
    "                break\n",
    "        uniform_tpr.append(this_tpr)\n",
    "        \n",
    "    uniform_fpr = np.array(uniform_fpr)\n",
    "    uniform_tpr = np.array(uniform_tpr)\n",
    "    \n",
    "    return uniform_fpr,uniform_tpr\n",
    "\n",
    "def get_bin_count(all_loss,all_label,bins=100,start=-10,stop=0,loss_transform=False):\n",
    "    #all_loss = np.exp(all_loss)\n",
    "    #all_loss = np.nan_to_num(all_loss,nan=0)\n",
    "    #print (np.amax(all_loss),np.amin(all_loss))\n",
    "    if (loss_transform):\n",
    "        all_loss = -1*all_loss*np.log(all_loss)\n",
    "    #print (np.amax(all_loss),np.amin(all_loss))\n",
    "    all_member_loss = all_loss[np.arange(len(all_label))[all_label == 1]]\n",
    "    all_nonmember_loss = all_loss[np.arange(len(all_label))[all_label == 0]]\n",
    "    bins = np.linspace(start=start,stop=stop,num=20)\n",
    "    member_count,_ = np.histogram(all_member_loss,bins=bins)\n",
    "    nonmember_count,_ = np.histogram(all_nonmember_loss,bins=bins)\n",
    "    \n",
    "    return member_count/sum(member_count),nonmember_count/sum(nonmember_count),bins[:-1]\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def test_eps(data_name):\n",
    "    #data = np.load('./expdata/cifar100_alexnet_1_200_0_0_0_0_0.0_0_0.0_loss_0.0_0.0_1_all_info.npz')\n",
    "    data = np.load(data_name)\n",
    "    all_prob = data['arr_0']\n",
    "    all_training_partition = data['arr_1']\n",
    "    all_validation_partition = data['arr_2']\n",
    "    all_class_label = data['arr_3']\n",
    "    #all_loss = data['arr_4']\n",
    "    #all_label = data['arr_5']\n",
    "    fpr_threshold = 1e-4\n",
    "    base_all_metric,base_all_label,_,_,_,_,avg_vul = get_blackbox_auc_lira(all_prob,all_training_partition, all_validation_partition, all_class_label)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    base_fpr,base_tpr = log_roc(base_all_metric,base_all_label)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(base_fpr,base_tpr,color='red')\n",
    "    plt.plot(base_fpr,base_fpr,color='blue')\n",
    "    plt.legend(['likelihood attack','random guess'])\n",
    "    #plt.xticks(np.log10(base_fpr))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(' roc curve w/o def')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(np.log10(base_fpr),base_tpr/base_fpr,color='red')\n",
    "    plt.plot(np.log10(base_fpr),base_fpr/base_fpr,color='blue')\n",
    "    plt.legend(['likelihood attack','random guess'])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('PLR')\n",
    "    plt.xticks(np.log10([1e-5,1e-4,1e-3,1e-2,1e-1,1]),labels=[\"$10^{-5}$\",\"$10^{-4}$\",\"$10^{-3}$\",\"$10^{-2}$\",\"$10^{-1}$\",\"1\"])\n",
    "    plt.title('roc curve at low FPR w/o def ')\n",
    "    plt.show()\n",
    "    return base_all_metric,base_all_label,avg_vul\n",
    "    \n",
    "def test_eps_loss(data_name):\n",
    "    \n",
    "    data = np.load(data_name)\n",
    "    all_prob = data['arr_0']\n",
    "    all_training_partition = data['arr_1']\n",
    "    all_validation_partition = data['arr_2']\n",
    "    all_class_label = data['arr_3']\n",
    "    all_loss = data['arr_4']\n",
    "    all_label = data['arr_5']\n",
    "    fpr_threshold = 1e-4\n",
    "    #base_all_metric,base_all_label,_,_,_,_ = get_blackbox_auc_lira(all_prob,all_training_partition, all_validation_partition, all_class_label)\n",
    "    \n",
    "    base_all_metric = all_loss\n",
    "    base_all_label = all_label\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    base_fpr,base_tpr = log_roc(base_all_metric,base_all_label)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(base_fpr,base_tpr,color='red')\n",
    "    plt.plot(base_fpr,base_fpr,color='blue')\n",
    "    plt.legend(['likelihood attack','random guess'])\n",
    "    #plt.xticks(np.log10(base_fpr))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.ylim(0,1)\n",
    "    plt.title(' roc curve w/o def')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(np.log10(base_fpr),base_tpr/base_fpr,color='red')\n",
    "    plt.plot(np.log10(base_fpr),base_fpr/base_fpr,color='blue')\n",
    "    plt.legend(['likelihood attack','random guess'])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('PLR')\n",
    "    plt.xticks(np.log10([1e-5,1e-4,1e-3,1e-2,1e-1,1]),labels=[\"$10^{-5}$\",\"$10^{-4}$\",\"$10^{-3}$\",\"$10^{-2}$\",\"$10^{-1}$\",\"1\"])\n",
    "    plt.title('roc curve at low FPR w/o def ')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e1fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps2 = 1e-25\n",
    "\n",
    "data_name = './expdata/cifar100_alexnet_1_200_0_0_0_0_0.0_0_0.0_loss_0.0_0.0_100_all_info.npz' \n",
    "metric,label,avg_vul = test_eps(data_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_index = np.argsort(avg_vul)[::-1][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92697466",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (avg_vul[top_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b2f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (top_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9980eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./cifar100_top500_vul_index.npy',np.array(top_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly sample 19500 instances from the rest \n",
    "all_index = np.arange(50000)\n",
    "rest_index = np.setdiff1d(all_index,top_index)\n",
    "sampled_rest_index = np.random.choice(rest_index,19000,replace=False)\n",
    "\n",
    "np.save('./cifar100_left19500_sample_index.npy',np.array(sampled_rest_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d3438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eps2 = 1e-25\n",
    "\n",
    "data_name = './expdata/cifar10_alexnet_1_200_0_0_0_0_0.0_0_0.0_loss_0.0_0.0_100_all_info.npz' \n",
    "metric,label,avg_vul = test_eps(data_name)\n",
    "top_index = np.argsort(avg_vul)[::-1][:1000]\n",
    "\n",
    "print (avg_vul[top_index])\n",
    "print (top_index)\n",
    "np.save('./cifar10_top500_vul_index.npy',np.array(top_index))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
