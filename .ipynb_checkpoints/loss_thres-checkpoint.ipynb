{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb3e22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logit_function(l):\n",
    "    ### we need to setup some bounds for probability (or loss) for numerical stability\n",
    "    eps = 1e-5\n",
    "    l = np.clip(l,a_min=eps,a_max=1-eps)\n",
    "    #print (l)\n",
    "    return np.log(l/(1-l))\n",
    "    \n",
    "import math\n",
    "def normpdf(x, mean, sd):\n",
    "    var = float(sd)**2\n",
    "    denom = (2*math.pi*var)**.5\n",
    "    num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "    return num/denom\n",
    "\n",
    "def get_blackbox_auc_lira(all_pred,all_train_index, all_valid_index, all_class_label, fpr_threshold=0.001):\n",
    "\t## prepare membership label and all probablities\n",
    "\tnum_instance = len(all_train_index[0]) + len(all_valid_index[0])\n",
    "\t\n",
    "\tall_metric_result = []\n",
    "\tall_labels = []\n",
    "\t\n",
    "\tfor i in range(num_instance):\n",
    "\t\t# prepare this instances label\n",
    "\t\t# prepare this instances pred\n",
    "\t\t#print (f\"instance index {i}\")\n",
    "\t\tthis_instance_pred = []\n",
    "\t\tthis_instance_label = []\n",
    "\t\tthis_instance_index = []\n",
    "\t\tthis_instance_prob = []\n",
    "\t\tfor j in range(len(all_train_index)):\n",
    "\t\t\tif (i in all_train_index[j]):\n",
    "\t\t\t\tthis_instance_label.append(1)\n",
    "\t\t\t\tthis_instance_index.append( all_train_index[j].tolist().index(i))\n",
    "\t\t\t\tthis_instance_pred.append( all_pred[j][this_instance_index[-1]])\n",
    "\t\t\t\tthis_pred = this_instance_pred[-1]\n",
    "\t\t\t\tthis_label = all_class_label[j][this_instance_index[-1]]\n",
    "\t\t\t\tthis_instance_prob.append( this_pred[this_label])\n",
    "\t\t\telse:\n",
    "\t\t\t\tthis_instance_label.append(0)\n",
    "\t\t\t\tthis_instance_index.append( all_valid_index[j].tolist().index(i) + len(all_train_index[j]))\n",
    "\t\t\t\tthis_instance_pred.append( all_pred[j][this_instance_index[-1]])\n",
    "\t\t\t\tthis_pred = this_instance_pred[-1]\n",
    "\t\t\t\tthis_label = all_class_label[j][this_instance_index[-1]]\n",
    "\t\t\t\tthis_instance_prob.append( this_pred[this_label])\n",
    "\t\t\t\n",
    "\t\tthis_instance_label = np.array(this_instance_label)\n",
    "\t\tthis_instance_index = np.array(this_instance_index)\n",
    "\t\tthis_instance_pred = np.array(this_instance_pred)\n",
    "\t\t\n",
    "\t\t#print (i,len(all_train_index),len(this_instance_label),len(this_instance_prob),len(this_instance_index))\n",
    "\t\t#print (this_instance_prob)\n",
    "\t\tthis_instance_prob = logit_function(np.array(this_instance_prob).flatten())\n",
    "\t\t\n",
    "\t\t#print (this_instance_prob)\n",
    "\t\t# select half of member and half of nonmember as training samples\n",
    "\t\t# remaining half of members and half of nonmembers are testing sample\n",
    "\t\thalf = int(0.5*len(this_instance_label))\n",
    "\t\t#print (half)\n",
    "\t\ttraining_index = np.random.choice(len(this_instance_label),half,replace=False)\n",
    "\t\ttesting_index = np.setdiff1d(np.arange(len(this_instance_label)),training_index)\n",
    "\n",
    "\t\ttraining_member_index = []\n",
    "\t\ttraining_nonmember_index = []\n",
    "\t\tfor this_idx in training_index:\n",
    "\t\t\tif (this_instance_label[this_idx] == 1):\n",
    "\t\t\t\ttraining_member_index.append(this_idx)\n",
    "\t\t\telse:\n",
    "\t\t\t\ttraining_nonmember_index.append(this_idx)\n",
    "\t\ttraining_nonmember_index = np.array(training_nonmember_index).astype(np.int64)\n",
    "\t\ttraining_member_index = np.array(training_member_index).astype(np.int64)\n",
    "\t\ttraining_member_prob = this_instance_prob[training_member_index]\n",
    "\t\ttraining_nonmember_prob = this_instance_prob[training_nonmember_index]\n",
    "\t\tin_mu,in_std = np.average(training_member_prob),np.std(training_member_prob)\n",
    "\t\t# calculate out distribution\n",
    "\t\tout_mu,out_std = np.average(training_nonmember_prob),np.std(training_nonmember_prob)\n",
    "\t\t# calculate metric\n",
    "\t\t#print (in_mu,in_std,out_mu,out_std)\n",
    "\t\tthis_instance_metric = []\n",
    "\t\tthis_instance_metric_label = []\n",
    "\t\teps = 1e-8\n",
    "\t\tfor idx in testing_index:\n",
    "\t\t\t#print (testing_index[idx])\n",
    "\t\t\t#print (len(this_instance_prob))\n",
    "\t\t\t#print (len(this_instance_label))\n",
    "\t\t\tthis_prob = this_instance_prob[idx]\n",
    "\t\t\tthis_label = this_instance_label[idx]\n",
    "\t\t\tin_prob = normpdf(this_prob,in_mu,in_std+eps) + eps\n",
    "\t\t\tout_prob = normpdf(this_prob,out_mu,out_std+eps) + eps\n",
    "\t\t\t#print (in_prob,out_prob)\n",
    "\t\t\tthis_metric = in_prob / out_prob\n",
    "\t\t\tthis_instance_metric.append(this_metric)\n",
    "\t\t\tthis_instance_metric_label.append(this_label)\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tall_metric_result.append(this_instance_metric)\n",
    "\t\tall_labels.append(this_instance_metric_label)\n",
    "\t\n",
    "\tall_metric_result = np.array(all_metric_result).flatten()\n",
    "\tall_metric_result = np.nan_to_num(all_metric_result)\n",
    "\tall_labels = np.array(all_labels).flatten()\n",
    "\t\n",
    "\tpos_index = np.arange(len(all_labels))[all_labels == 1]\n",
    "\tneg_index = np.arange(len(all_labels))[all_labels == 0]\n",
    "\tmin_len = min(len(pos_index),len(neg_index))\n",
    "\tsampled_pos_index = np.random.choice(pos_index,min_len,replace=False)\n",
    "\tsampled_neg_index = np.random.choice(neg_index,min_len,replace=False)\n",
    "\tsampled_index = np.concatenate((sampled_neg_index,sampled_pos_index),axis=0)\n",
    "\tall_metric_result = all_metric_result[sampled_index]\n",
    "\tall_labels = all_labels[sampled_index]\n",
    "\t#print (all_metric_result.shape,all_labels.shape)\n",
    "\t#print (all_metric_result[:100],all_labels[:100])\n",
    "\t## calcualte AUC and PLR\n",
    "\tauc = roc_auc_score(all_labels,all_metric_result)\n",
    "\tprint(f\"AUC score {auc}\")\n",
    "\tnegative_index = np.arange(len(all_labels))[all_labels == 0]\n",
    "\tthreshold_index = int(len(negative_index)*fpr_threshold)\n",
    "\tthreshold = np.sort(all_metric_result[negative_index])[::-1][threshold_index]\n",
    "\tprint(f\"Likelihood threshold {threshold}\")\n",
    "\t\n",
    "\tcnt = 0\n",
    "\tfor i in range(len(all_metric_result)):\n",
    "\t\tif (all_metric_result[i] >= threshold and all_labels[i]==1):\n",
    "\t\t\tcnt += 1\n",
    "\tprint(f\"TPR {cnt/len(negative_index)}, FPR {fpr_threshold}, PLR {cnt / threshold_index}\")\n",
    "\t\n",
    "\treturn all_metric_result,all_labels,auc,1.0*cnt/threshold_index\n",
    "\n",
    "\n",
    "def get_blackbox_auc_no_shadow(all_train_loss, all_test_loss, fpr_threshold=0.001):\n",
    "\t### randomly sample to get a balanced evaluation set\n",
    "\tmin_len = min(len(all_test_loss), len(all_train_loss))\n",
    "\ttest_index = np.random.choice(np.arange(len(all_test_loss)), min_len, replace=False)\n",
    "\tall_test_loss = all_test_loss[test_index]\n",
    "\ttrain_index = np.random.choice(np.arange(len(all_train_loss)), min_len, replace=False)\n",
    "\tall_train_loss = all_train_loss[train_index]\n",
    "\t\n",
    "\t## calcualte AUC and PLR\n",
    "\tlabel = np.concatenate((np.ones((len(all_train_loss))), np.zeros((len(all_test_loss)))))\n",
    "\tauc = roc_auc_score(label, np.concatenate((all_train_loss, all_test_loss), axis=0) * -1)\n",
    "\tprint(f\"AUC score {auc}\")\n",
    "\t\n",
    "\tthreshold = np.sort(all_test_loss)[int(len(all_test_loss) * fpr_threshold)]\n",
    "\tprint(f\"Loss threshold {threshold}\")\n",
    "\t\n",
    "\tcnt = 0\n",
    "\tfor i in range(len(all_train_loss)):\n",
    "\t\tif (all_train_loss[i] <= threshold):\n",
    "\t\t\tcnt += 1\n",
    "\tprint(f\"TPR {cnt / min_len}, FPR {fpr_threshold}, PLR {cnt / (min_len * fpr_threshold)}\")\n",
    "\t\n",
    "\treturn auc, 1.0 * cnt / (min_len * fpr_threshold), np.concatenate((all_train_loss, all_test_loss), axis=0) * -1, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f84b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50000, 100) (1, 50000)\n",
      "(20000,) (20000,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data = np.load('./expdata/cifar100_alexnet_1_200_0_0_0_0_0.0_0_0.0_loss_0.0_0.0_1_all_info.npz')\n",
    "all_prob = data['arr_0']\n",
    "all_training_partition = data['arr_1']\n",
    "all_validation_partition = data['arr_2']\n",
    "all_class_label = data['arr_3']\n",
    "all_loss = data['arr_4']\n",
    "all_label = data['arr_5']\n",
    "fpr_threshold = 0.001\n",
    "print (all_prob.shape,all_class_label.shape)\n",
    "print (all_loss.shape,all_label.shape)\n",
    "all_single_prob= []\n",
    "#for i in range(1):\n",
    "#    for j in range(50000):\n",
    "        #all_single_prob.append(all_prob[i][j][all_class_label[i][j]])\n",
    "        #all_single_prob.append(all_prob[i][j][all_class_label[i][j]])\n",
    "        \n",
    "all_single_prob = np.array(all_single_prob).flatten()\n",
    "print (all_single_prob.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14660359",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './expdata/cifar10_alexnet_1_200_0_0_0_0_3.5_1_0.0_loss_0.0_0.0_40_all_info.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#data = np.load('./expdata/cifar100_alexnet_1_200_0_0_0_0_0.0_0_0.0_loss_0.0_0.0_1_all_info.npz')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./expdata/cifar10_alexnet_1_200_0_0_0_0_3.5_1_0.0_loss_0.0_0.0_40_all_info.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m all_prob \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m all_training_partition \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marr_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/numpy/lib/npyio.py:407\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    405\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    408\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './expdata/cifar10_alexnet_1_200_0_0_0_0_3.5_1_0.0_loss_0.0_0.0_40_all_info.npz'"
     ]
    }
   ],
   "source": [
    "\n",
    "#data = np.load('./expdata/cifar100_alexnet_1_200_0_0_0_0_0.0_0_0.0_loss_0.0_0.0_1_all_info.npz')\n",
    "data = np.load('./expdata/cifar10_alexnet_1_200_0_0_0_0_3.5_1_0.0_loss_0.0_0.0_50_all_info.npz')\n",
    "all_prob = data['arr_0']\n",
    "all_training_partition = data['arr_1']\n",
    "all_validation_partition = data['arr_2']\n",
    "all_class_label = data['arr_3']\n",
    "all_loss = data['arr_4']\n",
    "all_label = data['arr_5']\n",
    "fpr_threshold = 0.001\n",
    "base_all_metric,base_all_label,_,_,_,_ = get_blackbox_auc_lira(all_prob,all_training_partition, all_validation_partition, all_class_label,fpr_threshold=fpr_threshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2129d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
