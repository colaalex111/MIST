{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   \n",
    "def report_acc(data,label):    \n",
    "    \n",
    "    unique_labels = np.unique(label)\n",
    "    train_index = []\n",
    "    for this_label in unique_labels:\n",
    "        this_class_index = np.arange(len(label))[label == this_label]\n",
    "        this_class_train_index = np.random.choice(this_class_index,int(len(this_class_index)/2),replace=False)\n",
    "        train_index.append(this_class_train_index)\n",
    "    train_index = np.reshape(np.array(train_index),(-1))\n",
    "    test_index = np.setdiff1d(np.arange(len(label)),train_index)\n",
    "\n",
    "    train_data = data[train_index]\n",
    "    train_label = label[train_index]\n",
    "    test_data = data[test_index]\n",
    "    test_label = label[test_index]\n",
    "\n",
    "    train_data = np.reshape(train_data, (len(train_label), -1))\n",
    "    test_data = np.reshape(test_data, (len(test_label),-1))\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    clf = LogisticRegression(random_state=0, solver='liblinear',class_weight='balanced')\n",
    "    clf.fit(train_data, train_label)\n",
    "    acc1 = balanced_accuracy_score(test_label,clf.predict(test_data))\n",
    "    f1_1 = f1_score(test_label,clf.predict(test_data), average='weighted')\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=100,max_depth=30, random_state=0,class_weight=\"balanced\")\n",
    "\n",
    "    clf.fit(train_data, train_label)\n",
    "    acc2 = balanced_accuracy_score(test_label,clf.predict(test_data))\n",
    "    f1_2 = f1_score(test_label,clf.predict(test_data), average='weighted')\n",
    "    \n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    clf = MLPClassifier(solver='sgd', alpha=0.01,hidden_layer_sizes=(50, len(unique_labels)), random_state=1)\n",
    "    clf.fit(train_data,train_label)\n",
    "    acc3 = balanced_accuracy_score(test_label,clf.predict(test_data))\n",
    "\n",
    "    return max(acc1,acc2,acc3)\n",
    "\n",
    "\n",
    "def all_analysis(epochs,name_prefix,dataset,model,eval_data_size,special_layers=None,num_layers=12,num_user=5,gap=0):\n",
    "    target_data_size = 5000\n",
    "    total_data_num = (num_user+1)*eval_data_size\n",
    "    all_epoch_cos = np.zeros((total_data_num,len(epochs),num_user))\n",
    "    all_epoch_loss = np.zeros((total_data_num,len(epochs),num_user))\n",
    "    all_epoch_target_loss = np.zeros((total_data_num,len(epochs),num_user))\n",
    "    all_epoch_grad_diff = np.zeros((total_data_num,len(epochs),num_user))\n",
    "    all_epoch_layer_cos = np.zeros((total_data_num,len(epochs),num_user,num_layers))\n",
    "    all_epoch_layer_grad_diff = np.zeros((total_data_num,len(epochs),num_user,num_layers))\n",
    "    all_epoch_target_after_loss = np.zeros((total_data_num,len(epochs),num_user))\n",
    "    all_epoch_label = np.zeros(total_data_num)\n",
    "    best_layer_dict = {'cifar100':6,'cifar10':2}\n",
    "    this_best_layer = best_layer_dict[dataset]\n",
    "    \n",
    "    for epoch_idx,epoch in enumerate(epochs):\n",
    "        data_name = prefix+'all_info_multi_party_member_attack_'+str(gap)+'_'+str(num_user)+'_0_0.0_0_0.0_0_'+str(epoch+1)+'_'+str(dataset)+'_'+str(target_data_size)+'_'+str(eval_data_size)+'_'+str(model)+'.npy'\n",
    "        data = np.load(data_name,allow_pickle=True)\n",
    "        label_name = prefix+'all_label_multi_party_member_attack_'+str(gap)+'_'+str(num_user)+'_0_0.0_0_0.0_0_'+str(epoch+1)+'_'+str(dataset)+'_'+str(target_data_size)+'_'+str(eval_data_size)+'_'+str(model)+'.npy'\n",
    "        label = np.load(label_name)\n",
    "        loss_data_name = prefix+'loss_info_multi_party_member_attack_'+str(gap)+'_'+str(num_user)+'_0_0.0_0_0.0_0_'+str(epoch+1)+'_'+str(dataset)+'_'+str(target_data_size)+'_'+str(eval_data_size)+'_'+str(model)+'.npy'\n",
    "        loss_data = np.load(loss_data_name,allow_pickle=True)\n",
    "        loss_label_name = prefix+'loss_label_multi_party_member_attack_'+str(gap)+'_'+str(num_user)+'_0_0.0_0_0.0_0_'+str(epoch+1)+'_'+str(dataset)+'_'+str(target_data_size)+'_'+str(eval_data_size)+'_'+str(model)+'.npy'\n",
    "        loss_label = np.load(loss_label_name,allow_pickle=True)\n",
    "        \n",
    "        target_loss_data_name = prefix+'target_model_before_loss_info_multi_party_member_attack_'+str(gap)+'_'+str(num_user)+'_0_0.0_0_0.0_0_'+str(epoch+1)+'_'+str(dataset)+'_'+str(target_data_size)+'_'+str(eval_data_size)+'_'+str(model)+'.npy'\n",
    "        target_loss_data = np.load(target_loss_data_name,allow_pickle=True)\n",
    "        target_after_loss_data_name = prefix+'target_model_after_loss_info_multi_party_member_attack_'+str(gap)+'_'+str(num_user)+'_0_0.0_0_0.0_0_'+str(epoch+1)+'_'+str(dataset)+'_'+str(target_data_size)+'_'+str(eval_data_size)+'_'+str(model)+'.npy'\n",
    "        target_after_loss_data = np.load(target_loss_data_name,allow_pickle=True)\n",
    "        data = np.reshape(data,(-1,num_user,12,14))\n",
    "        label = np.reshape(label,(-1))\n",
    "        loss_data = np.reshape(loss_data,(-1,num_user))\n",
    "        loss_label = np.reshape(loss_label,(-1))\n",
    "        target_loss_data = np.reshape(target_loss_data,(-1,1))\n",
    "        target_loss_data = np.tile(target_loss_data,(1,num_user))\n",
    "        target_after_loss_data = np.reshape(target_after_loss_data,(-1,1))\n",
    "        target_after_loss_data = np.tile(target_after_loss_data,(1,num_user))\n",
    "        #print (data.shape,label.shape,loss_data.shape,loss_label.shape,target_loss_data.shape)\n",
    "        \n",
    "        all_epoch_cos[:,epoch_idx,:] = data[:,:,this_best_layer,0]\n",
    "        all_epoch_grad_diff[:,epoch_idx,:] = data[:,:,this_best_layer,1] - data[:,:,this_best_layer,2]\n",
    "        all_epoch_layer_cos[:,epoch_idx,:,:] = data[:,:,:,0]\n",
    "        all_epoch_layer_grad_diff[:,epoch_idx,:,:] = data[:,:,:,1] - data[:,:,:,2]\n",
    "        all_epoch_loss[:,epoch_idx,:] = loss_data\n",
    "        all_epoch_target_loss[:,epoch_idx,:] = target_loss_data\n",
    "        all_epoch_target_after_loss[:,epoch_idx,:] = target_after_loss_data\n",
    "        all_epoch_label = label\n",
    "        \n",
    "        \n",
    "    all_epoch_analysis(all_epoch_cos,all_epoch_grad_diff,all_epoch_loss,all_epoch_target_loss,all_epoch_target_after_loss,all_epoch_label,member_index = num_user*eval_data_size)\n",
    "       \n",
    "        \n",
    "def all_epoch_analysis(all_epoch_cosine,all_epoch_grad_diff,all_epoch_loss,all_epoch_target_loss,all_epoch_target_after_loss,label,member_index):\n",
    "    ### for all epoch analysis and member-only case, we would like to see the following attacks:\n",
    "    # 1. sum of loss, argmin\n",
    "    # 2. sum of cosine, argmax\n",
    "    # 3. sum of grad-diff, argmax\n",
    "    # 4. all loss, NN\n",
    "    # 5. all cosine, NN\n",
    "    # 6. all grad-diff, NN\n",
    "    # 7. sum of loss, sum of cosine, sum of grad-diff, NN\n",
    "    # 8. all loss, all cosine, all grad-diff, NN\n",
    "    # 9. sum of sign of loss reduction, argmax\n",
    "    # 10. sum of loss, sum of cosine, sum of grad-diff, sum of sign of loss reduction, NN\n",
    "    import copy\n",
    "    num_instance = all_epoch_cosine.shape[0]\n",
    "    \n",
    "    #print (num_instance)\n",
    "    \n",
    "    max_acc = 0\n",
    "    print (\"member only case\")\n",
    "    #1\n",
    "    metric = np.sum(all_epoch_loss,axis=1)\n",
    "    this_acc = accuracy_score(np.argmin(metric[:member_index],axis=1),label[:member_index])\n",
    "    #print (f\"sum of loss acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "\n",
    "    #2 \n",
    "    metric = np.sum(all_epoch_cosine,axis=1)\n",
    "    this_acc = accuracy_score(np.argmax(metric[:member_index],axis=1),label[:member_index])\n",
    "    #print (f\"sum of cosine acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "\n",
    "    #3\n",
    "    metric = np.sum(all_epoch_grad_diff,axis=1)\n",
    "    this_acc = accuracy_score(np.argmax(metric[:member_index],axis=1),label[:member_index])\n",
    "    #print (f\"sum of grad diff acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "\n",
    "    #11 grad_diff / loss\n",
    "    # p = e^(-L), grad multiplier = p - 1\n",
    "    multiplier = 1 - np.exp(-1*all_epoch_loss) \n",
    "    metric = np.sum(all_epoch_grad_diff/multiplier,axis=1)\n",
    "    this_acc = accuracy_score(np.argmax(metric[:member_index],axis=1),label[:member_index])\n",
    "    #print (f\"sum of grad_diff/loss acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "\n",
    "    #4\n",
    "    metric = np.reshape(copy.deepcopy(all_epoch_loss),(num_instance,-1))\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"all epoch loss acc {this_acc}\")    \n",
    "    max_acc = max(max_acc,this_acc)\n",
    "\n",
    "    #5\n",
    "    metric = np.reshape(copy.deepcopy(all_epoch_cosine),(num_instance,-1))\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"all epoch cosine acc {this_acc}\")   \n",
    "    max_acc = max(max_acc,this_acc)\n",
    "\n",
    "    #6\n",
    "    metric = np.reshape(copy.deepcopy(all_epoch_grad_diff),(num_instance,-1))\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"all epoch grad diff acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "    \n",
    "    #7\n",
    "    metric = np.concatenate((np.sum(all_epoch_loss,axis=1),\n",
    "                             np.sum(all_epoch_cosine,axis=1),\n",
    "                             np.sum(all_epoch_grad_diff,axis=1)),axis=1)\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"all epoch sum acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "    \n",
    "    #8\n",
    "    metric = np.concatenate((np.reshape(copy.deepcopy(all_epoch_loss),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_cosine),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_grad_diff),(num_instance,-1))),axis=1)\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"all epoch loss+cosine+grad_diff acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "    \n",
    "    #9\n",
    "    loss_reduction = all_epoch_target_after_loss - all_epoch_loss\n",
    "    loss_reduction = np.reshape(copy.deepcopy(loss_reduction),(num_instance,-1))\n",
    "    #loss_reduction_sign_metric = np.sum(sign_loss_reduction,axis=1)\n",
    "    #print (loss_reduction_sign_metric)\n",
    "    metric = loss_reduction\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"sum of loss reduction acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "    \n",
    "    #10\n",
    "    metric = np.concatenate((np.reshape(copy.deepcopy(all_epoch_loss),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_cosine),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_grad_diff),(num_instance,-1)),\n",
    "                            np.reshape(copy.deepcopy(loss_reduction),(num_instance,-1))),axis=1)\n",
    "    this_acc = report_acc(metric[:member_index],label[:member_index])\n",
    "    #print (f\"all epoch loss+cosine+grad_diff+loss_reduction acc {this_acc}\")\n",
    "    max_acc = max(max_acc,this_acc)\n",
    "    \n",
    "    print (f\"MAXIMUM ACC {max_acc}\")\n",
    "    \n",
    "    max_acc = 0\n",
    "    ### for non-member including case, we need to consider the following attacks:\n",
    "    #1. sum loss \n",
    "    #2. all loss\n",
    "    #3. sum cos\n",
    "    #4. all cos\n",
    "    #5. sum grad diff\n",
    "    #6. all grad diff\n",
    "    #7. all feature\n",
    "    print (\"testing instances included\")\n",
    "    #1\n",
    "    metric = np.sum(all_epoch_loss,axis=1)\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"sum of loss acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #2 \n",
    "    metric = np.sum(all_epoch_cosine,axis=1)\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"sum of cosine acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #3\n",
    "    metric = np.sum(all_epoch_grad_diff,axis=1)\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"sum of grad diff acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #4\n",
    "    metric = np.reshape(copy.deepcopy(all_epoch_loss),(num_instance,-1))\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"all epoch loss acc {this_acc}\")   \n",
    "    max_acc = max(this_acc,max_acc) \n",
    "    \n",
    "    #5\n",
    "    metric = np.reshape(copy.deepcopy(all_epoch_cosine),(num_instance,-1))\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"all epoch cosine acc {this_acc}\")   \n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #6\n",
    "    metric = np.reshape(copy.deepcopy(all_epoch_grad_diff),(num_instance,-1))\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"all epoch grad diff acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #7\n",
    "    metric = np.concatenate((np.sum(all_epoch_loss,axis=1),\n",
    "                             np.sum(all_epoch_cosine,axis=1),\n",
    "                             np.sum(all_epoch_grad_diff,axis=1)),axis=1)\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"all epoch sum acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #8\n",
    "    metric = np.concatenate((np.reshape(copy.deepcopy(all_epoch_loss),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_cosine),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_grad_diff),(num_instance,-1))),axis=1)\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"all epoch loss+cosine+grad_diff acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    \n",
    "    #9\n",
    "    loss_reduction = all_epoch_target_after_loss - all_epoch_loss\n",
    "    loss_reduction = np.reshape(copy.deepcopy(loss_reduction),(num_instance,-1))\n",
    "    #loss_reduction_sign_metric = np.sum(sign_loss_reduction,axis=1)\n",
    "    #print (loss_reduction_sign_metric)\n",
    "    metric = loss_reduction\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"sum of loss reduction acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "\n",
    "    #10\n",
    "    metric = np.concatenate((np.reshape(copy.deepcopy(all_epoch_loss),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_cosine),(num_instance,-1)),\n",
    "                             np.reshape(copy.deepcopy(all_epoch_grad_diff),(num_instance,-1)),\n",
    "                            np.reshape(copy.deepcopy(loss_reduction),(num_instance,-1))),axis=1)\n",
    "    this_acc = report_acc(metric,label)\n",
    "    #print (f\"all epoch loss+cosine+grad_diff+loss_reduction acc {this_acc}\")\n",
    "    max_acc = max(this_acc,max_acc)\n",
    "    print (f\"MAXIMUM ACC {max_acc}\")\n",
    "    \n",
    "\n",
    "def per_layer_analysis(all_epoch_cosine,all_epoch_grad_diff,all_epoch_loss,all_epoch_target_loss,label,all_epoch_layer_cosine,all_epoch_layer_grad_diff,member_index):\n",
    "    ### for per layer analysis, we want to see the difference between 1. loss 2. csoine 3. grad_diff for member only case\n",
    "    \n",
    "    num_layers = all_epoch_layer_cosine.shape[-1]\n",
    "    num_instance = all_epoch_cosine.shape[0]\n",
    "    num_epoch = all_epoch_cosine.shape[1]\n",
    "    num_user = all_epoch_cosine.shape[2]    \n",
    "    eval_data_size = 5000\n",
    "    \n",
    "    print (\"member only case\")\n",
    "    \n",
    "    all_epoch_loss_acc = []\n",
    "    all_epoch_cos_acc = []\n",
    "    all_epoch_grad_diff_acc = []\n",
    "    \n",
    "    for epoch_idx in range(num_epoch):\n",
    "        #print (f\"epoch:{epoch_idx*10}\")\n",
    "        layer_cosine_acc = []\n",
    "        layer_grad_diff_acc = []\n",
    "        this_epoch_loss = all_epoch_loss[:,epoch_idx,:]\n",
    "        for layer_idx in range(num_layers):\n",
    "            this_layer_cosine = all_epoch_layer_cosine[:,epoch_idx,:,layer_idx]\n",
    "            this_layer_grad_diff = all_epoch_layer_grad_diff[:,epoch_idx,:,layer_idx]\n",
    "            layer_cosine_acc.append(accuracy_score(np.argmax(this_layer_cosine,axis=1)[:member_index],label[:member_index]))\n",
    "            layer_grad_diff_acc.append(accuracy_score(np.argmax(this_layer_grad_diff,axis=1)[:member_index],label[:member_index]))\n",
    "        loss_acc = accuracy_score(np.argmin(this_epoch_loss,axis=1)[:member_index],label[:member_index])\n",
    "        \n",
    "        #fig = plt.figure(figsize=(5,5))\n",
    "        #plt.plot(np.arange(num_layers),layer_cosine_acc)\n",
    "        #plt.plot(np.arange(num_layers),layer_grad_diff_acc)\n",
    "        #plt.plot(np.arange(num_layers),[loss_acc for i in range(num_layers)])\n",
    "        #plt.legend(['cosine','grad-diff','loss'])\n",
    "        #plt.show()\n",
    "        \n",
    "        all_epoch_loss_acc.append(loss_acc)\n",
    "        all_epoch_cos_acc.append(max(layer_cosine_acc))\n",
    "        all_epoch_grad_diff_acc.append(max(layer_grad_diff_acc))\n",
    "                                           \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.plot(np.arange(num_epoch)*10,all_epoch_cos_acc)\n",
    "    plt.plot(np.arange(num_epoch)*10,all_epoch_grad_diff_acc)\n",
    "    plt.plot(np.arange(num_epoch)*10,all_epoch_loss_acc)\n",
    "    plt.legend(['cosine','grad-diff','loss'])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print (\"testing instances included\")\n",
    "    \n",
    "    all_epoch_loss_acc = []\n",
    "    all_epoch_cos_acc = []\n",
    "    all_epoch_grad_diff_acc = []\n",
    "    \n",
    "    for epoch_idx in range(num_epoch):\n",
    "        #print (f\"epoch:{epoch_idx*10}\")\n",
    "        layer_cosine_acc = []\n",
    "        layer_grad_diff_acc = []\n",
    "        this_epoch_loss = all_epoch_loss[:,epoch_idx,:]\n",
    "        for layer_idx in range(num_layers):\n",
    "            this_layer_cosine = all_epoch_layer_cosine[:,epoch_idx,:,layer_idx]\n",
    "            this_layer_grad_diff = all_epoch_layer_grad_diff[:,epoch_idx,:,layer_idx]\n",
    "            layer_cosine_acc.append(report_acc(this_layer_cosine,label))\n",
    "            layer_grad_diff_acc.append(report_acc(this_layer_grad_diff,label))\n",
    "        loss_acc = report_acc(this_epoch_loss,label)\n",
    "        \n",
    "        #fig = plt.figure(figsize=(5,5))\n",
    "        #plt.plot(np.arange(num_layers),layer_cosine_acc)\n",
    "        #plt.plot(np.arange(num_layers),layer_grad_diff_acc)\n",
    "        #plt.plot(np.arange(num_layers),[loss_acc for i in range(num_layers)])\n",
    "        #plt.legend(['cosine','grad-diff','loss'])\n",
    "        #plt.show()\n",
    "        \n",
    "        all_epoch_loss_acc.append(loss_acc)\n",
    "        all_epoch_cos_acc.append(max(layer_cosine_acc))\n",
    "        all_epoch_grad_diff_acc.append(max(layer_grad_diff_acc))\n",
    "                                           \n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.plot(np.arange(num_epoch)*10,all_epoch_cos_acc)\n",
    "    plt.plot(np.arange(num_epoch)*10,all_epoch_grad_diff_acc)\n",
    "    plt.plot(np.arange(num_epoch)*10,all_epoch_loss_acc)\n",
    "    plt.legend(['cosine','grad-diff','loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = np.array([2,3,4,5,6,7,8,9,10])\n",
    "prefix = '/Users/jclialex/PycharmProjects/whiteboxmi_expdata/expdata/expdata/'\n",
    "epochs = ((np.arange(29)+1)*10)\n",
    "\n",
    "for this_gap in gap:\n",
    "    print (f\"active attacker gradien ascent every {this_gap} epoch\")\n",
    "    all_analysis(epochs,prefix,'cifar10','alexnet',200,num_user=3,gap=this_gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "a = [[[1,2],[3,4]],[[5,6],[7,8]]]\n",
    "a = np.array(a)\n",
    "print (a.shape)\n",
    "print (np.vstack(a).shape)\n",
    "print (np.hstack(a).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
